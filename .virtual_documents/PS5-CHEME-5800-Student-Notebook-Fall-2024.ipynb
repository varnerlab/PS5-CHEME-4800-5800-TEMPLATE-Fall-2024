





include("Include.jl");





function U(x::Tuple{Int,Int}, Î±::Array{Float64,1})::Float64
    
    # get the apples, and oranges 
    apples = x[1];
    oranges = x[2];
    
    # compute the objective -
    utility = (apples^Î±[1])*(oranges^Î±[2]);
    
    # return -
    return utility;
end;





# initialize -
Î± = [0.55, 0.45]; # coefficients
c = [0.98, 1.49]; # price of x1 and x2
total_budget = 50.0;

# build my problem object -
base = nothing

# call the solve function. This will return a dictionary -
base_solution = solve(base);


base_solution





optimal_apples = base_solution["argmax"][1] |> x-> round(x,digits=0) |> Int
optimal_oranges = base_solution["argmax"][2] |> x-> round(x,digits=0) |> Int
println("(apples, oranges) = ($(optimal_apples),$(optimal_oranges))")








number_of_rows = nothing # TODO: fill me in
number_of_cols = nothing # TODO: fill me in
nactions = nothing; # TODO: fill me in
nstates = nothing; # TODO: fill me in
ğ’® = range(1,stop=nstates,step=1) |> collect;
ğ’œ = range(1,stop=nactions,step=1) |> collect;
Î³ = 0.95;
k_max = 250;





my_objective_value = nothing; # TODO: call the U(...) function
rewards = Dict{Tuple{Int,Int}, Float64}()
rewards[(optimal_apples, optimal_oranges)] = my_objective_value;

# setup set of absorbing states -
absorbing_state_set = Set{Tuple{Int,Int}}()
push!(absorbing_state_set, (optimal_apples, optimal_oranges));





world = build(MyRectangularGridWorldModel, 
    (nrows = number_of_rows, ncols = number_of_cols, rewards = rewards));





R = zeros(nstates, nactions);
fill!(R, 0.0)

# Update R: Fill in data from the world model
for s âˆˆ ğ’®
    for a âˆˆ ğ’œ
        
        Î” = world.moves[a];
        current_position = world.coordinates[s]
        new_position =  current_position .+ Î”
        
        # TODO: fill me in
    end
end

# Update R: setup soft walls. These will be our budget constraints
soft_wall_set = Set{Tuple{Int,Int}}();
for s âˆˆ ğ’®
    
    # get the position -
    current_position = world.coordinates[s]
    
    # TODO: current_position violate the budget? (with a 1 USD grace)?
    # TODO: Hint: think about this like a penalty function
    # if yes, store this position in the soft_wall_set
end

# Update R: Do we drive off the world?
for s âˆˆ ğ’®
    current_position = world.coordinates[s]
    for a âˆˆ ğ’œ
        Î” = world.moves[a];
        new_position =  current_position .+ Î”
        
        if (in(new_position, soft_wall_set) == true)
          R[s,a] = -1000.0  
        end
    end
end





# --- DO NOT CHANGE ME .... STEP AWAY FROM YOUR KEYBOARD --------------- #
T = Array{Float64,3}(undef, nstates, nstates, nactions);
fill!(T, 0.0)
for a âˆˆ ğ’œ
    
    Î” = world.moves[a];
    
    for s âˆˆ ğ’®
        current_position = world.coordinates[s]
        new_position =  current_position .+ Î”
        if (haskey(world.states, new_position) == true && 
                in(current_position, absorbing_state_set) == false)
            sâ€² = world.states[new_position];
            T[s, sâ€²,  a] = 1.0
        else
            T[s, s,  a] = 1.0
        end
    end
end
# --------------------------------------------------------------------- #





m = build(MyMDPProblemModel, (ğ’® = ğ’®, ğ’œ = ğ’œ, T = T, R = R, Î³ = Î³));





value_iteration_model = MyValueIterationModel(k_max); # takes k_max as argument
solution = nothing





my_Q = Q(m, solution.U)





my_Ï€ = policy(my_Q);








let
    # draw the path -
    p = plot();
    hit_absorbing_state = false
    s = world.states[initial_site];
    visited_sites = Set{Tuple{Int,Int}}();
    push!(visited_sites, initial_site);
    
    while (hit_absorbing_state == false)
        current_position = world.coordinates[s]
        a = my_Ï€[s];
        Î” = world.moves[a];
        new_position =  current_position .+ Î”
        scatter!([current_position[1]],[current_position[2]], label="", showaxis=:false, msc=:black, c=:blue)
        plot!([current_position[1], new_position[1]],[current_position[2], new_position[2]], label="", arrow=true, lw=1, c=:red)
        
        if (in(new_position, absorbing_state_set) == true || in(new_position, visited_sites) == true)
            hit_absorbing_state = true;
        else
            s = world.states[new_position];
            push!(visited_sites, new_position);
        end
    end
    
    # draw the grid -
    for s âˆˆ ğ’®
        current_position = world.coordinates[s]
        a = my_Ï€[s];
        Î” = world.moves[a];
        new_position =  current_position .+ Î”
        
        if (haskey(rewards, current_position) == true && rewards[current_position] == my_objective_value)
            scatter!([current_position[1]],[current_position[2]], label="Optimal: $(current_position)", c=:green, ms=4, legend=:bottomleft)
        elseif (in(current_position, soft_wall_set) == true)
            scatter!([current_position[1]],[current_position[2]], label="", showaxis=:false, c=:gray69, ms=4)
        else
            scatter!([current_position[1]],[current_position[2]], label="", showaxis=:false, msc=:gray50, c=:white)
        end
    end
    xlabel!("Number of Apples",fontsize=18)
    ylabel!("Number of Oranges",fontsize=18)
    current()
end



